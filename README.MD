# RAG with LLAMAINDEX

## Introduction

    - * Retrieve * Most Relevant Data
    - * Augment * query with context
    - * Generate * resonse.
    - * Contextual Integration : RAG apps load context into a Database, then retrieve content to insert into the prompt.

 Addressing a shortcoming found in LLMS

## Vectors

Vector space .
Tuning words in numbers called Embeddings.

## create-llama

[npx create-llama](https://www.npmjs.com/package/create-llama) to create a bootstrap app with llamaindex as a nextjs app 